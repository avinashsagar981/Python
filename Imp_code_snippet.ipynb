{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxQdGle0TzcUuacQB2OqZE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avinashsagar981/Python/blob/main/Imp_code_snippet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** How to use enumerate function ***"
      ],
      "metadata": {
        "id": "nWUpOqIY3aq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"cat in the hat dog on the mat bird in the tree\"\n",
        "\n",
        "a = text.split()\n",
        "\n",
        "for i, word in enumerate(a): # or for i, word in enumerate(a,1) so it start with index 1\n",
        "  print(i, word)\n",
        "\n",
        "# or\n",
        "b = {i:word for i, word in enumerate(a)}\n",
        "b"
      ],
      "metadata": {
        "id": "OxRmDoZK3W3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_1RdtjpC3X0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **One Hot Encoding**"
      ],
      "metadata": {
        "id": "aA3oNIhE_EaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(text):\n",
        "    words = text.split()\n",
        "    vocabulary = set(words)\n",
        "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "    one_hot_encoded = []\n",
        "    for word in words:\n",
        "        one_hot_vector = [0] * len(vocabulary)\n",
        "        one_hot_vector[word_to_index[word]] = 1\n",
        "        one_hot_encoded.append(one_hot_vector)\n",
        "    return one_hot_encoded, word_to_index, vocabulary\n",
        "\n",
        "example_text = \"cat in the hat dog on the mat bird in the tree\"\n",
        "\n",
        "one_hot_encoded, word_to_index, vocabulary = one_hot_encode(example_text)\n",
        "\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "print(\"Word to Index Mapping:\", word_to_index)\n",
        "print(\"One-Hot Encoded Matrix:\")\n",
        "for word, encoding in zip(example_text.split(), one_hot_encoded):\n",
        "    print(f\"{word}: {encoding}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C32D_kZ6sQ_M",
        "outputId": "590f111b-241a-4c97-bf48-16954b4b547f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'dog', 'cat', 'hat', 'tree', 'on', 'the', 'bird', 'in', 'mat'}\n",
            "Word to Index Mapping: {'dog': 0, 'cat': 1, 'hat': 2, 'tree': 3, 'on': 4, 'the': 5, 'bird': 6, 'in': 7, 'mat': 8}\n",
            "One-Hot Encoded Matrix:\n",
            "cat: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "in: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "the: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "hat: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "dog: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "on: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "the: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "mat: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "bird: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "in: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "the: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "tree: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding Implementation with Detailed Explanation\n",
        "\n",
        "def one_hot_encode(text):\n",
        "    # LINE 1: Split the input text into individual words using spaces as delimiters\n",
        "    # Example: \"cat in the hat\" becomes [\"cat\", \"in\", \"the\", \"hat\"]\n",
        "    words = text.split()\n",
        "\n",
        "    # LINE 2: Create a set from the words list to get unique words only\n",
        "    # Sets automatically remove duplicates, so \"the\" appears only once\n",
        "    # Example: {\"cat\", \"in\", \"the\", \"hat\", \"dog\", \"on\", \"mat\", \"bird\", \"tree\"}\n",
        "    vocabulary = set(words)\n",
        "\n",
        "    # LINE 3: Create a dictionary mapping each unique word to an index number\n",
        "    # enumerate() gives us (index, word) pairs starting from 0\n",
        "    # Dictionary comprehension creates {word: index} mapping\n",
        "    # Example: {\"cat\": 0, \"in\": 1, \"the\": 2, \"hat\": 3, ...}\n",
        "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "\n",
        "    # LINE 4: Initialize empty list to store one-hot vectors for each word\n",
        "    one_hot_encoded = []\n",
        "\n",
        "    # LINE 5: Loop through each word in the original text (including duplicates)\n",
        "    for word in words:\n",
        "        # LINE 6: Create a vector of zeros with length equal to vocabulary size\n",
        "        # This creates a list like [0, 0, 0, 0, 0, 0, 0, 0, 0] for 9 unique words\n",
        "        one_hot_vector = [0] * len(vocabulary)\n",
        "\n",
        "        # LINE 7: Set the position corresponding to current word's index to 1\n",
        "        # If \"cat\" has index 0, then one_hot_vector[0] = 1\n",
        "        # Result: [1, 0, 0, 0, 0, 0, 0, 0, 0] for \"cat\"\n",
        "        one_hot_vector[word_to_index[word]] = 1\n",
        "\n",
        "        # LINE 8: Add this one-hot vector to our result list\n",
        "        one_hot_encoded.append(one_hot_vector)\n",
        "\n",
        "    # LINE 9: Return the encoded vectors, word-to-index mapping, and vocabulary\n",
        "    return one_hot_encoded, word_to_index, vocabulary\n",
        "\n",
        "# EXECUTION SECTION:\n",
        "\n",
        "# LINE 10: Define example text with repeated words\n",
        "example_text = \"cat in the hat dog on the mat bird in the tree\"\n",
        "\n",
        "# LINE 11: Call the function and unpack the three returned values\n",
        "one_hot_encoded, word_to_index, vocabulary = one_hot_encode(example_text)\n",
        "\n",
        "# LINE 12-13: Print the unique vocabulary (unordered set)\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "\n",
        "# LINE 14-15: Print the word-to-index mapping dictionary\n",
        "print(\"Word to Index Mapping:\", word_to_index)\n",
        "\n",
        "# LINE 16-18: Print each word with its corresponding one-hot vector\n",
        "print(\"One-Hot Encoded Matrix:\")\n",
        "for word, encoding in zip(example_text.split(), one_hot_encoded):\n",
        "    print(f\"{word}: {encoding}\")\n",
        "\n",
        "# WHAT THIS CODE DOES:\n",
        "# 1. Takes text input and converts each word to a one-hot encoded vector\n",
        "# 2. One-hot encoding represents each word as a binary vector where:\n",
        "#    - Vector length = size of vocabulary (unique words)\n",
        "#    - Only one position is 1 (hot), rest are 0 (cold)\n",
        "#    - Each word gets a unique position that's always 1\n",
        "# 3. This is commonly used in NLP for converting text to numerical format\n",
        "#    that machine learning models can process"
      ],
      "metadata": {
        "id": "XCwOie-csRCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding\n",
        "\n",
        "It can be identified as one of the simplest forms of representing words numerically. Each word is represented as a binary vector with the length of the entire vocabulary. The vector has a “1” in the position corresponding to the word’s index and “0” elsewhere.\n",
        "###### **Pro’s:** Simple, interpretable.\n",
        "##### **Con’s:** High dimensionality, doesn’t capture semantic relationships."
      ],
      "metadata": {
        "id": "RKZgsg9WKScf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "corpus = ['dog', 'cat', 'dog', 'fish']\n",
        "\n",
        "# Reshape data to fit the model\n",
        "corpus = np.array(corpus).reshape(-1, 1)\n",
        "\n",
        "# One-hot encode the data\n",
        "onehot_encoder = OneHotEncoder()\n",
        "onehot_encoded = onehot_encoder.fit_transform(corpus)\n",
        "\n",
        "print(onehot_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqmpn9p7KJYC",
        "outputId": "d7a85ce8-2b22-484e-dd7b-2a2b8fcde403"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 4 stored elements and shape (4, 3)>\n",
            "  Coords\tValues\n",
            "  (0, 1)\t1.0\n",
            "  (1, 0)\t1.0\n",
            "  (2, 1)\t1.0\n",
            "  (3, 2)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7gTrsNpAKJk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to update this file on github"
      ],
      "metadata": {
        "id": "_np5oyvnaRfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GITHUB"
      ],
      "metadata": {
        "id": "S2PFJFcTXQNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyGithub\n",
        "!pip install PyGithub"
      ],
      "metadata": {
        "id": "n2vSeLTYaW1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from github import Github\n",
        "import json\n",
        "\n",
        "# Authenticate\n",
        "g = Github(userdata.get('Github_Token'))\n",
        "\n",
        "# Get repository\n",
        "repo = g.get_repo(\"avinashsagar981/Python\")\n",
        "\n",
        "# Read notebook content\n",
        "with open('Imp_code_snippet.ipynb', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "try:\n",
        "    # Try to get existing file\n",
        "    file = repo.get_contents(\"Imp_code_snippet.ipynb\")\n",
        "    # Update existing file\n",
        "    repo.update_file(\"Imp_code_snippet.ipynb\", \"Update from Colab\", content, file.sha)\n",
        "    print(\"✅ File updated successfully!\")\n",
        "except:\n",
        "    # Create new file if it doesn't exist\n",
        "    repo.create_file(\"Imp_code_snippet.ipynb\", \"Create from Colab\", content)\n",
        "    print(\"✅ File created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ3W58mEXOnm",
        "outputId": "6df4ec11-ae70-42b0-edbf-9f50d3ad9387"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File updated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updatted!!!"
      ],
      "metadata": {
        "id": "Jhu5M5yCbAdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 12345"
      ],
      "metadata": {
        "id": "O_jSFsztad1P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7QXv7TjJZ_Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mxm_eWZXO1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVRlsd3zXO4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cl63_45-XO7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJGyvu5uXO_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rQ4HAvGXPDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-nq7FIXXPGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xv39E1BTXPJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gps6uXUHXPNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYvQXPlvXPQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tECg4RI8XPUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7dpb5lXKJoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8aDFV7UFKJrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-q4ukNTKJy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-S45EG2cKJ1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvbTjYDwKJ5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xzpTa6nHKJ8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FeFva0cYKJ_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JPbRLHVDKKCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZI0hXeYsSOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwudP1EVsSRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zzno5ryQsSZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGOBLJDwsSc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LmKZxdSUsSgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xtToGlLosSkR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}